#!/bin/bash

#SBATCH --partition=gpu_titanrtx_shared_course
#SBATCH --gres=gpu:1
#SBATCH --job-name=LightGCN-Amazon-SDPA-4
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=3
#SBATCH --time=48:00:00
#SBATCH --mem=32000M
#SBATCH --output=../out/slurm_output_%x.out

module purge
module load 2021
module load Anaconda3/2021.05

# activate the environment
source activate lightgcn-gpu

cd $HOME/LightGCN/code
wandb online

num_layers=(4)

for nl in "${num_layers[@]}"; do
    srun python -u main.py \
        --model "sdp-a-lgn" \
        --topks "[1, 2, 3, 5, 10, 20]" \
        --dataset "amazon-book" \
        --lr 0.001 \
        --decay 0.0001 \
        --seed 2020 \
        --recdim 64 \
        --batch_size 2048 \
        --save_embs \
        --layer $nl
done

