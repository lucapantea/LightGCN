#!/bin/bash

#SBATCH --partition=gpu_titanrtx_shared_course
#SBATCH --gres=gpu:1
#SBATCH --job-name=LightGCN-Appnp-Gowalla-4
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=3
#SBATCH --time=48:00:00
#SBATCH --mem=32000M
#SBATCH --output=../out/slurm_output_%x.out

module purge
module load 2021
module load Anaconda3/2021.05

# activate the environment
source activate lightgcn-gpu

cd $HOME/LightGCN/code
wandb online

num_layers=(4)

for nl in "${num_layers[@]}"; do
    srun python -u main.py \
        --model "appnp" \
        --topks "[1, 2, 3, 5, 10, 20]" \
        --dataset "gowalla" \
        --lr 0.001 \
        --decay 0.0001 \
        --seed 2020 \
        --recdim 64 \
        --batch_size 1024 \
        --layer $nl \
        --alpha 0.1 \
        --num_walks 25
done

