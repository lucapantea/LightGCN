#!/bin/bash

#SBATCH --partition=gpu_titanrtx_shared_course
#SBATCH --gres=gpu:1
#SBATCH --job-name=LightGCN-Amazon-WSDPA-4
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=3
#SBATCH --time=48:00:00
#SBATCH --mem=32000M
#SBATCH --output=../out/slurm_output_%x.out

module purge
module load 2021
module load Anaconda3/2021.05

# activate the environment
source activate lightgcn-gpu

cd $HOME/LightGCN/code
wandb online

attention_dims=(8)
num_layers=(4)

for ad in "${attention_dims[@]}"; do
    for nl in "${num_layers[@]}"; do
        srun python -u main.py \
            --model "w-sdp-a-lgn" \
            --attention_dim $ad \
            --dataset "amazon-book" \
            --lr 0.001 \
            --decay 0.0001 \
            --seed 2020 \
            --recdim 64 \
            --batch_size 2048 \
            --save_embs \
            --layer $nl
    done
done

