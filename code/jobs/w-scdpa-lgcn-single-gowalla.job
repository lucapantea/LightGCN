#!/bin/bash

#SBATCH --partition=gpu_titanrtx_shared_course
#SBATCH --gres=gpu:1
#SBATCH --job-name=LightGCN-Gowalla-WSDPA-single
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=3
#SBATCH --time=48:00:00
#SBATCH --mem=32000M
#SBATCH --output=../out/slurm_output_%x.out

module purge
module load 2021
module load Anaconda3/2021.05

# activate the environment
source activate lightgcn-gpu

cd $HOME/LightGCN/code
wandb online

attention_dims=(8)
num_layers=(1 2 3 4)

for ad in "${attention_dims[@]}"; do
    for nl in "${num_layers[@]}"; do
        srun python -u main.py \
            --model "w-sdp-a-lgn" \
            --attention_dim $ad \
            --single \
            --dataset "gowalla" \
            --lr 0.001 \
            --decay 0.0001 \
            --seed 2020 \
            --recdim 64 \
            --batch_size 1024 \
            --layer $nl
    done
done

